{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DocChat 案例介绍\n",
    "得益于大模型优秀的zero/few shot learning能力，当前可通过将特定Documents((PDF, blog, Notion pages等)作为Context传入模型，从而快速适配特定领域知识并应用,这一场景可大致统一为DocChat。\n",
    "\n",
    "将原始文档等非结构化数据转化并实现DocChat大致可分为以下几步：\n",
    "\n",
    "- Loading 加载：首先，我们需要加载数据。非结构化数据可以从多个来源加载。使用LangChain集成中心浏览完整的加载器集合。每个加载器将数据返回为LangChain文档。\n",
    "\n",
    "- Splitting 分割：文本分割器将文档拆分为指定大小的片段。\n",
    "\n",
    "- Storage 存储：存储（例如矢量存储）将保存并常常嵌入这些片段。\n",
    "\n",
    "- Retireval 检索：应用程序从存储中检索片段（通常具有与输入问题相似的嵌入特征）。\n",
    "\n",
    "- Generation 生成：语言模型生成一个答案，使用的提示包括问题和检索到的数据。\n",
    "\n",
    "- Conbersation：通过在问答链中添加记忆（Memory），进行多轮对话。\n",
    "\n",
    "我们使用网络上获得的流程作为演示，它很好的解释了上面的过程。\n",
    "\n",
    "从不同工具和组件的角度来看：\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./img/langchain+chatglm.png\" alt=\"Image\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "从文档的角度来看：\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./img/langchain+chatglm2.png\" alt=\"Image\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "\n",
    "接下来我们将基于langchain复现DocChat的整体流程,这里将侧重于对于langchain关键组件的使用和介绍，默认环境已正确配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. Load**  \n",
    "langchain 提供了一系列的工具来支持 CSV, FileDirectory, HTML, Json等格式的文本载入，同时提供一系列集成工具以实现AWS S3, Arxiv, Email, Github， Google BigQuery等100+平台数据接入，具体支持清单可参考[官方文档](https://python.langchain.com/docs/integrations/document_loaders/)\n",
    "\n",
    "这里我们使用特定的`DocumentLoader`(WebBaseLoader 和 xx ) 将非结构化数据载入为`Documents`, 每个`Document`由一系列文本片段(`page_content`字段)和相关元数据组成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\\n\\n\\n\\n\\nopenEuler社区参与之旅\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n博客openEuler社区参与之旅openEuler社区参与之旅openEuler2023-06-30openEuler欢迎来到openEuler！签署CLA #您必须首先签署签署CLA协议，然后才能参与社区贡献。根据您的参与身份，选择签署个人 CLA、员工 CLA 或企业 CLA。协议的签署地址是：https://clasign.osinfra.cn/sign/gitee_openeuler-1611298811283968340\\xa0安装openEuler #请参考[下载安装openEuler]开始您的贡献 #签署好协议以后，就需要考虑在社区里具体能做点什么了。参与社区有很多种方法和形式，如果总结起来，大体有下面的三类：1.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0提交一些需求，或者bug，简单来说就是在用openEuler的过程中发现了一些问题，然后需要在社区把这个问题提出来。2.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0为社区修正bug，这是更高一个层面的参与社区了，在这个层面，参与者实质上是以一个开发者的姿态进入到了社区中。一般我们都提倡，除了提出问题，更期待大家能解决问题。3.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0贡献软件包，发现openEuler缺失了一个软件包，帮openEuler把这个软件包补上。实际上贡献软件包的过程就是帮助openEuler提供更丰富功能的过程。希望随着大家的参与，openEuler能够成为一个\"无所不有\"的软件生态系统。我们就来看看这3种参与方式如何进行吧。在具体讨论参与方法之前，大家可以先保存下面三个网址链接。openEuler官网：https://openeuler.org/openEuler代码仓：\\xa0https://gitee.com/openeuler/openEuler软件包仓：https://gitee.com/src-openeuler第一个网址是openEuler的官网，是供大家获取一些通用信息的地方。而真正我们所谓的\"社区\"则是体现在2，3这两个网址上。提出问题或建议（提Issue） #如果您发现并想向社区上报问题或缺陷，问题提交的方式就是创建一个Issue。您只要将问题以Issue的方式提交到该项目Repository的Issue列表内，并查看[Issue提交指南]以获取更多的信息。提交问题时，请尽量遵守问题提交准则。Issue有两个渠道 一个是Gitee 一个是 QuickIssue。openEuler社区的所有issue都可以通过QuickIssue提交，并且可以按图索骥找仓库，优化了查找issue归属仓库的途径。如果您认为长时间没有得到回应，可以向邮箱[community@openeuler.org]求助。提交一个PR #如果要参与代码贡献，您还需要了解如何在Gitee下载代码，通过PR合入代码等。openEuler使用的是Gitee代码托管平台，了解具体的指导请参考[Gitee Workflow Guide]。新增软件包 #操作步骤：通过修改Gitee中在openeuler/community仓库实现新增软件包，具体操作步骤如下：1.点击进入community仓库，将其fork到自己的仓库。2.将fork完成的community仓库clone到本地。3.修改community仓库。明确软件包所属的sig组，如zip属于Base-service组（请参考SIG列表找到您感兴趣的SIG或项目）；修改所属sig文件夹下的内容，如项目清单等；修改所属sig文件夹下的sig-info.yaml，将要新增的软件包以\"- src-openeuler/zip\"的形式添加到对应的sig组列表下；以zip为例，修改sig/Base-service/sig-info.yaml：建仓，在 sig/{sig目录}/src-openeuler/软件名首字母 新增下对应的yaml文件(openeuler社区维护项目: openeuler目录；其他社区引入包: src-openeuler目录。示例参考：sig/Base-service/src-openeuler/z/zip.yaml)你要做的就是把文件修改了，然后提交PR就可以了。要在commit message里解释清楚为什么要添加这样一个包，或者为什么要创建这样一个仓库。commit message写的越好，越容易通过审核\\xa0。PR合入后将会在gitee建立同名仓库。查看地址：src-openeuler。具体流程可参考[如何新增软件包]。EUR #EUR(openEuler User Repo)是openEuler社区针对开发者推出的个人软件包托管平台，目的在于为开发者提供一个易用的软件包分发平台.链接：https://eur.openeuler.openatom.cn/如何使用openEuler用户仓（视频）：https://b23.tv/sKHjKUU测试测试------是所有贡献者的责任，对于社区版本来说，sig-qa组是负责测试活动的社区官方组织。如果您希望在自己的基础架构上开展测试活动，可以参考：社区测试体系介绍。为了成功发行一个社区版本，需要完成多种测试活动。不同的测试活动，测试代码的位置也有所不同，成功运行测试所需的环境的细节也会有差异，有关的信息可以参考[测试指南]。选择社区组件打包您也可以参与社区组件打包，请参考：[如何打包]社区安全问题披露[安全处理流程]------简要描述了处理安全问题的过程[安全披露信息]------如果您希望报告安全漏洞，请参考此页面找到您感兴趣的组织 #了解SIGSIG就是Special Interest Group的缩写，openEuler社区按照不同的SIG来组织，以便于更好的管理和改善工作流程。SIG组是开放的，欢迎任何人加入并参与贡献。SIG都是针对特定的一个或多个技术主题而成立的。SIG内的成员推动交付成果输出，并争取让交付成果成为openEuler社区发行的一部分。SIG的核心成员主导SIG的治理。请查看[SIG的角色说明]。您可以在贡献的同时积累经验和提升影响力。每一个SIG在Gitee上都会拥有一个或多个项目，这些项目会拥有一个或多个Repository。SIG的交付成果会保存在这些Repository内。可以在SIG对应的Repository内提交Issue、针对特定问题参与讨论，提交和解决问题，参与评审等。您也可以通过邮件列表、IRC或视频会议和SIG内的成员进行交流。找到您感兴趣的SIG或项目找到您感兴趣的SIG组，可以帮助您在正确的地方提出问题，并得到更快的社区响应。方式一：如果您不了解有哪些SIG或项目，您可以查看[SIG列表]，它包含当前openEuler社区成立的所有SIG团队的清单。您可以通过该列表快速的定位到您感兴趣的领域所对应SIG团队。同时还为您提供该SIG团队的如下信息：SIG下的项目，以及项目的Repository地址SIG内的交流方式，包括邮件列表、IRC会议频道等Maintainer的联系方式方式二：如果您知道感兴趣的项目名称，可以在openEuler的Repository列表下进行模糊搜索，从而快速定位到对应项目的首页地址。通常情况下，在该项目首页地址的README.md文件中，可以找到该项目所属的SIG信息、交流方式、成员和联系方式等。如果上述两种方式都定位不到您感兴趣的SIG，您可以向[community@openeuler.org]发求助邮件。建议您在邮件列表内用\"【开发过程疑问】\"作为标题，在内容中写出你寻找的SIG或项目的特征，我们会为您提供帮助。参与社区活动 #社区内沟通方式openEuler社区的交流方式有邮件列表和视频会议等1. 访问该地址https://www.openeuler.org/zh/community/mailing-list/找到社区可用的邮件列表，请根据您的兴趣参照下面步骤去加入某个邮件列表。2. 访问该地址：https://www.openeuler.org/zh/可以看到社区各SIG的例会安排，点击相关链接还可查看会议链接和会议纪要，欢迎感兴趣的开发者找到对应的SIG组，申报议题和参会。社区新闻和大事件openEuler参加或举办的社区和技术交流会议，关于这些事件和其他社区事件信息均可以在[openEuler新闻]页面上找到社区聚会社区每年会定期举办开发者大会，您可以通过[https://openeuler.org]上的信息或通过电子邮件[dev@openeuler.org]与我们联系。来加入我们吧~问题反馈如果您在使用该贡献者指南或对开发过程有疑问，请随时通过电子邮件[dev@openeuler.org]与我们联系，并在邮件标题内用\"【开发过程疑问】\"作为邮件标题写出你的疑问和困惑，openEuler社区运营团队会并尽力确保您的问题得到解答。【版权声明】Copyright © 2023 openEuler Community。本文由openEuler社区首发，欢迎遵照 CC-BY-SA 4.0 协议规定转载。转载时敬请在正文注明并保留原文链接和作者信息。【免责声明】本文仅代表作者本人观点，与本网站无关。本网站对文中陈述、观点判断保持中立，不对所包含内容的准确性、可靠性或完整性提供任何明示或暗示的保证。本文仅供读者参考，由此产生的所有法律责任均由读者本人承担。openEuler 是由开放原子开源基金会（OpenAtom Foundation）孵化及运营的开源项目contact@openeuler.io品牌隐私政策法律声明服务状态版权所有 © 2023 openEuler 保留一切权利遵循 木兰宽松许可证第2版（MulanPSL2）openEuler公众号openEuler小助手quickissueQuick Issueicon/robot欧拉 小智欧拉 论坛\\n\\n\\n\\n', metadata={'source': 'https://www.openeuler.org/zh/blog/20230630-newcomer/0630-newcomer.html', 'title': 'openEuler社区参与之旅', 'description': 'openEuler 是一个开源、免费的 Linux 发行版平台，将通过开放的社区形式与全球的开发者共同构建一个开放、多元和架构包容的软件生态体系。同时，openEuler 也是一个创新的平台，鼓励任何人在该平台上提出新想法、开拓新思路、实践新方案。', 'language': 'zh'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.openeuler.org/zh/blog/20230630-newcomer/0630-newcomer.html\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. Split**   \n",
    "将`Document`分割为特定大小文本块用于embedding 和 vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. Store**  \n",
    "为了能够查找已拆分的文档，我们首先需要将它们存储在方便查询的位置。最常用的方法是将每个文档的内容 embedding ，然后将 embedding 和文档存储在向量存储中，其中使用 embedding 来索引文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. Retrieve**  \n",
    "langchain提供了很多类别的 Retrievers, 包含但不限于 Vectorstores，所有的 Retrievers都实现了 `get_relevant_documents()`和异步版本 `aget_relevant_documents()` 实现文档检索。这里我们使用相似度搜索从 Vectorstores 检索与问题相关的分割的文档块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"如何参与社区活动?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于距离的向量数据库检索将查询嵌入到高维空间中，并根据\"距离\"找到类似的嵌入式文档。但是，如果查询措辞稍有变化，或者嵌入式未能很好地捕捉数据的语义，检索结果可能会产生不同的结果。`MultiQueryRetriever`通过使用语言模型（LLM）自动生成多个具有不同角度的查询，从而自动化提示调优过程。对于每个查询，它检索一组相关文档，并在所有查询之间取唯一并集，以获得一个更大的潜在相关文档集合。通过对同一问题生成多个视角，`MultiQueryRetriever`可能能够克服基于距离的检索的某些限制，并获得更丰富的结果集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectorstore.as_retriever(),\n",
    "                                                  llm=ChatOpenAI(temperature=0))\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5. Generate**  \n",
    "在使用langchain过程中数据会频繁的在Loaders, Models, Vectorstores, Agent等组件间流动，针对特定场景对工具的调用和数据传输遵守特定流程，因此langchain提供了`chain`组件实现对于工具的固定编排，从而在特定任务上快速开发。 这里我们使用`RetrievalQA` chain 与LLM/Chat模型（例如gpt-3.5-turbo）将检索到的文档提炼成答案。\n",
    "注意：由于chat模型在输入输出中通常包含固定格式(普遍为 [{\"role\": \"user\", \"message\": \"hello.\"}...] ), 在langchain中 将 chat模型和 LLM (输入输出均为字符串) 作为不同类型。langchain当前提供55 个chat模型和LLM, 详见[清单](https://python.langchain.com/docs/integrations/llms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '如何参与社区活动?',\n",
       " 'result': '参与openEuler社区活动有以下几个步骤：\\n\\n1. 签署CLA协议：首先，您需要签署CLA协议，才能参与社区贡献。根据您的参与身份，选择签署个人CLA、员工CLA或企业CLA。协议的签署地址是：https://clasign.osinfra.cn/sign/gitee_openeuler-1611298811283968340\\n\\n2. 下载安装openEuler：请参考[下载安装openEuler]开始您的贡献。\\n\\n3. 选择参与方式：根据您的兴趣和技能，选择以下三种参与方式之一：\\n   - 提交需求或bug：在使用openEuler的过程中，如果发现了问题或有改进建议，可以在社区中提交需求或bug报告。\\n   - 修正bug：如果您是开发者，可以参与到社区中，修复已知的bug，提高openEuler的质量。\\n   - 贡献软件包：如果发现openEuler缺失了某个软件包，您可以帮助openEuler补充这个软件包，丰富openEuler的功能。\\n\\n4. 参考网址链接：在具体讨论参与方法之前，您可以保存以下三个网址链接，以便获取更多信息：\\n   - openEuler官网：https://openeuler.org/openEuler\\n   - openEuler代码仓：https://gitee.com/openeuler/openEuler\\n   - 软件包仓：https://gitee.com/src-op\\n\\n5. 社区内沟通方式：openEuler社区的交流方式包括邮件列表和视频会议等。您可以访问https://www.openeuler.org/zh/community/mailing-list/，找到社区可用的邮件列表，并根据您的兴趣加入某个邮件列表。\\n\\n希望以上信息对您有帮助，祝您在openEuler社区的参与之旅愉快！'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever())\n",
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optional 1:*   \n",
    "同样可以使用我们部署的 `chatGLM` 来实现答案生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '如何参与社区活动?',\n",
       " 'result': 'To participate in community activities, you can follow these steps:\\n\\n1. Submit requirements or bugs: You can submit requirements or bugs to the openEuler community through the openEuler website, code repository, or email list.\\n2. 修正 bugs: As a developer, you can contribute to the openEuler community by fixing bugs. You can also participate in the openEuler code repository to contribute new code or fix existing code.\\n3. 贡献 software包： To help the openEuler community, you can contribute software包 by finding missing software包 or fixing bugs in the openEuler code repository.\\n\\nOverall, there are various ways to participate in the openEuler community, and the best way to do so will depend on your interests and experience.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import ChatGLM\n",
    "\n",
    "# default endpoint_url for a local deployed ChatGLM api server\n",
    "endpoint_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# direct access endpoint in a proxied environment\n",
    "# os.environ['NO_PROXY'] = '127.0.0.1'\n",
    "\n",
    "llm_chatglm = ChatGLM(\n",
    "    endpoint_url=endpoint_url,\n",
    "    max_token=80000,\n",
    "    top_p=0.9,\n",
    "    model_kwargs={\"sample_model_args\": False},\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm_chatglm,retriever=vectorstore.as_retriever())\n",
    "qa_chain({\"query\": question})\n",
    "\n",
    "# turn on with_history only when you want the LLM object to keep track of the conversation history\n",
    "# and send the accumulated context to the backend model api, which make it stateful. By default it is stateless.\n",
    "# llm.with_history = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optional 2:*   \n",
    "在部分场景中我们可能需要对`chain`中涉及的`prompt`进行调整，新的`prompt`可以通过参数传递给对应的`chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'要参与openEuler社区活动，您可以通过以下三种方式之一：1. 提交需求或bug，将在使用openEuler过程中发现的问题提出来。2. 修复bug，以开发者的身份参与社区，解决问题。3. 贡献软件包，帮助openEuler提供更丰富的功能。感谢您的提问！'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optional 3:*   \n",
    "在基于文档生成答案时受限于模型能力，准确率差异化较大，且文档切片可能导致关键信息不完整，因此在问答中提供文档源和链接可有效提升问答效果，保障信息准确性。`RetrievalQAWithSourcesChain` 提供了这部分能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '如何参与社区活动?',\n",
       " 'answer': '参与社区活动有三种方式：\\n1. 提交需求或bug：在使用openEuler的过程中，发现问题或bug后，可以在社区中提出并讨论。\\n2. 修正bug：以开发者的身份参与社区，解决问题和修复bug。\\n3. 贡献软件包：发现openEuler缺失某个软件包时，可以帮助补充该软件包，为openEuler提供更丰富的功能。\\n\\n参与社区活动的具体方法可以参考以下链接：\\n- openEuler官网：https://openeuler.org/openEuler\\n- openEuler代码仓：https://gitee.com/openeuler/openEuler\\n- 软件包仓：https://gitee.com/src-op\\n\\n在openEuler社区中，可以通过邮件列表和视频会议等方式进行交流和沟通。具体步骤可以参考以下链接：\\n- 社区可用的邮件列表：https://www.openeuler.org/zh/community/mailing-list/\\n\\n参与社区活动前，需要首先签署CLA协议。根据参与身份的不同，可以选择签署个人CLA、员工CLA或企业CLA。协议签署地址为：https://clasign.osinfra.cn/sign/gitee_openeuler-1611298811283968340\\n\\n安装openEuler并开始贡献的详细步骤可以参考链接：[下载安装openEuler]\\n\\n',\n",
       " 'sources': '- https://www.openeuler.org/zh/blog/20230630-newcomer/0630-newcomer.html'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm,retriever=vectorstore.as_retriever())\n",
    "\n",
    "result = qa_chain({\"question\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optional 4:*   \n",
    "检索到的文档可以通过几种不同的方式输入到LLM中进行答案提炼: `stuff`, `refine`, `map-reduce`, and `map-rerank`.\n",
    "stuff: 将列表中文档的内容均作为上下文传入。\n",
    "Refine: 通过循环输入列表中文档并迭代更新其答案。\n",
    "map-reduce: 首先对每个文档分别应用LLM链（Map步骤），将链的输出作为一个新文档。然后，它将所有新文档传递给一个单独的合并文档链以获得单一输出（Reduce步骤）。\n",
    "map-rerank: 对每个文档运行prompt，不仅尝试完成任务，还会给出答案的置信度评分。返回最高得分的回答。\n",
    "\n",
    "可以通过 `chain_type` 参数为`RetrievalQA` 设置文档输入模式."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '如何参与社区活动?', 'result': '参与openEuler社区活动有以下几个步骤：\\n\\n1. 签署CLA协议：首先，您需要签署CLA协议，才能参与社区贡献。根据您的参与身份，选择签署个人CLA、员工CLA或企业CLA。协议的签署地址是：https://clasign.osinfra.cn/sign/gitee_openeuler-1611298811283968340\\n\\n2. 下载安装openEuler：请参考[下载安装openEuler]开始您的贡献。\\n\\n3. 提交需求或bug：在使用openEuler的过程中，如果发现了问题或有需求，您可以在社区中提交这些问题。您可以访问openEuler官网（https://openeuler.org/openEuler）并在其中找到相应的邮件列表，根据您的兴趣加入某个邮件列表，然后在邮件列表中提出您的问题或需求。\\n\\n4. 修正bug：如果您是开发者，您可以通过修正bug来参与社区。在openEuler的代码仓（https://gitee.com/openeuler/openEuler）中，您可以找到需要修复的bug，并提交您的修复代码。\\n\\n5. 贡献软件包：如果您发现openEuler缺失了某个软件包，您可以帮助openEuler补充这个软件包。您可以在openEuler的软件包仓（https://gitee.com/src-op）中查找相关信息，并提交您的贡献。\\n\\n希望以上步骤能帮助您参与openEuler社区活动。'}\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever(),\n",
    "                                       chain_type=\"stuff\")\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6. Conversation**  \n",
    "为了进行对话，`chain`需要能够引用过去的交流记录。`Memory` 使我们能够实现这一点。为了保留历史聊天记录，我们可以指定一个内存缓冲区来跟踪对话的输入和输出。在` ConversationalRetrievalChain`中使用 `memory`中的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'要参与openEuler的活动，您可以按照以下步骤进行：\\n\\n1. 首先，您需要签署openEuler的CLA协议。根据您的参与身份，选择签署个人CLA、员工CLA或企业CLA。您可以访问https://clasign.osinfra.cn/sign/gitee_openeuler-1611298811283968340来签署协议。\\n\\n2. 安装openEuler。您可以参考[下载安装openEuler]的指南来开始您的贡献。\\n\\n3. 参与社区的讨论和交流。openEuler社区有邮件列表和视频会议等交流方式。您可以访问https://www.openeuler.org/zh/community/mailing-list/来找到可用的邮件列表，并根据您的兴趣加入某个邮件列表。\\n\\n4. 根据您的兴趣和能力，选择参与的方式。您可以提交需求或bug，为社区修正bug，或贡献软件包。具体的参与方法可以在openEuler官网（https://openeuler.org/openEuler）、openEuler代码仓（https://gitee.com/openeuler/openEuler）和软件包仓（https://gitee.com/src-op）上找到。\\n\\n希望以上信息对您有帮助，祝您在openEuler社区的参与之旅愉快！'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chat = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)\n",
    "\n",
    "result = chat({\"question\": \"openeuler是什么？\"})\n",
    "result['answer']\n",
    "\n",
    "# The Memory buffer has context to resolve \"openeuler\" in the below question.\n",
    "result = chat({\"question\": \"如何参与它的活动？\"})\n",
    "result['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
